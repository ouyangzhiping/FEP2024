{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62750596-cd39-4850-bb07-5c6d329eae08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Prior Distribution over States:\n",
      "[0.5 0.5]\n",
      " \n",
      "State Prediction Error:\n",
      "[-0.17548846 -0.96897099]\n",
      " \n",
      "Depolarization:\n",
      "[-0.86863564 -1.66211817]\n",
      " \n",
      "Posterior Distribution over States:\n",
      "[0.68857861 0.31142139]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from spm.spm_softmax import spm_softmax\n",
    "\n",
    "\n",
    "# 设置模型以计算状态预测误差\n",
    "A = np.array([[0.8, 0.4],       \n",
    "              [0.2, 0.6]])         # 似然\n",
    "\n",
    "B_t1 = np.array([[0.9, 0.2], \n",
    "                 [0.1, 0.8]])      # 前一时间步的转移先验\n",
    "    \n",
    "B_t2 = np.array([[0.2, 0.3], \n",
    "                 [0.8, 0.7]])      # 当前时间步的转移先验\n",
    "    \n",
    "o = np.array([1, 0])               # 观测\n",
    "\n",
    "s_pi_tau = np.array([0.5, 0.5])    # 状态的先验分布\n",
    "s_pi_tau_minus_1 = np.array([0.5, 0.5])\n",
    "s_pi_tau_plus_1 = np.array([0.5, 0.5])\n",
    "\n",
    "v_0 = np.log(s_pi_tau)             # 去极化项（初始值）\n",
    "\n",
    "B_t2_cross_intermediate = B_t2.T   # 转置 B_t2\n",
    "\n",
    "B_t2_cross = spm_softmax(B_t2_cross_intermediate) # 归一化转置 B_t2 的列\n",
    "\n",
    "# 计算状态预测误差（单次迭代）\n",
    "state_error = 0.5 * (np.log(B_t1 @ s_pi_tau_minus_1) + np.log(B_t2_cross @ s_pi_tau_plus_1)) \\\n",
    "              + np.log(A.T @ o) - np.log(s_pi_tau) # 状态预测误差\n",
    "\n",
    "v = v_0 + state_error             # 去极化\n",
    "\n",
    "s = np.exp(v) / np.sum(np.exp(v)) # 更新后的状态分布\n",
    "\n",
    "print(' ')\n",
    "print('Prior Distribution over States:')\n",
    "print(s_pi_tau)\n",
    "print(' ')\n",
    "print('State Prediction Error:')\n",
    "print(state_error)\n",
    "print(' ')\n",
    "print('Depolarization:')\n",
    "print(v)\n",
    "print(' ')\n",
    "print('Posterior Distribution over States:')\n",
    "print(s)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ea73af9-cd15-448d-a45f-4a272b5d43c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Risk Under Policy 1:\n",
      "2.408606420911068\n",
      " \n",
      "Risk Under Policy 2:\n",
      "7.30685276317247\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# 设置模型以计算结果预测误差\n",
    "# 这最小化期望自由能（最大化奖励和信息增益）\n",
    "\n",
    "# 计算两种策略下的风险（寻求奖励）\n",
    "\n",
    "A = np.array([[0.9, 0.1],\n",
    "              [0.1, 0.9]])   # 似然\n",
    " \n",
    "S1 = np.array([0.9, 0.1])    # 策略1下的状态\n",
    "S2 = np.array([0.5, 0.5])    # 策略2下的状态\n",
    "\n",
    "C = np.array([1, 0])         # 首选结果\n",
    "\n",
    "o_1 = A @ S1                 # 策略1下的预测结果\n",
    "o_2 = A @ S2                 # 策略2下的预测结果\n",
    "z = np.exp(-16)              # 添加到偏好分布中的小数以避免 log(0)\n",
    "\n",
    "risk_1 = np.dot(o_1, np.log(o_1) - np.log(C + z)) # 策略1下的风险\n",
    "\n",
    "risk_2 = np.dot(o_2, np.log(o_2) - np.log(C + z)) # 策略2下的风险\n",
    "\n",
    "print(' ')\n",
    "print('Risk Under Policy 1:')\n",
    "print(risk_1)\n",
    "print(' ')\n",
    "print('Risk Under Policy 2:')\n",
    "print(risk_2)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5382fd7a-e9a0-4285-b4d4-7313f131e644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Ambiguity Under Policy 1:\n",
      "0.6557507426621495\n",
      " \n",
      "Ambiguity Under Policy 2:\n",
      "0.5176633478852948\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# 计算两种策略下的模糊性（寻求信息）\n",
    "\n",
    "A = np.array([[0.4, 0.2],\n",
    "              [0.6, 0.8]])   # 似然\n",
    " \n",
    "s1 = np.array([0.9, 0.1])    # 策略1下的状态\n",
    "s2 = np.array([0.1, 0.9])    # 策略2下的状态\n",
    "\n",
    "ambiguity_1 = -np.dot(np.diag(A.T @ np.log(A)), s1) # 策略1下的模糊性\n",
    "\n",
    "ambiguity_2 = -np.dot(np.diag(A.T @ np.log(A)), s2) # 策略2下的模糊性\n",
    "\n",
    "print(' ')\n",
    "print('Ambiguity Under Policy 1:')\n",
    "print(ambiguity_1)\n",
    "print(' ')\n",
    "print('Ambiguity Under Policy 2:')\n",
    "print(ambiguity_2)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c10ecd8-41b3-4b65-99ed-2f3d1972c7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
